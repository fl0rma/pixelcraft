{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0833ef14-20e2-47b0-9dd0-e206494ed2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cfc65-54f6-4cd2-a33c-8bca6f1415f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 1. Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d2f5be-f23c-4e08-892a-77ccad76e6e3",
   "metadata": {},
   "source": [
    "#inputs from user\n",
    "\n",
    "print(\"What type of pattern do you want?\")\n",
    "print(\"Option 1: Lego Pattern\")\n",
    "print(\"Option 2: Cross Stich Pattern\")\n",
    "\n",
    "choice = input(\"Enter the number of your choice: \")\n",
    "\n",
    "if choice == \"1\":\n",
    "    desired_pattern = \"lego\"\n",
    "elif choice == \"2\":\n",
    "    desired_pattern = \"cross_stich\"\n",
    "else:\n",
    "    print(\"Invalid choice. Please enter a valid option (1 or 2).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e50bbc-34b4-4e52-9542-b9dfee8edc81",
   "metadata": {},
   "source": [
    "#inputs from user\n",
    "while True:\n",
    "    if desired_pattern == \"lego\":\n",
    "        print(\"How many pieces, each conforming to the width of the desired image, will there be?\")\n",
    "        count = input(\"Enter the number: \")\n",
    "        \n",
    "        # Attempt to convert the input to an integer\n",
    "        try:\n",
    "            count = int(count)\n",
    "            break  # Exit the loop if conversion to int is successful\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid integer.\")\n",
    "    else:\n",
    "        print(\"How many stitches, each conforming to the width of the desired image, will there be?\")\n",
    "        count = input(\"Enter the number: \")\n",
    "        \n",
    "        # Attempt to convert the input to an integer\n",
    "        try:\n",
    "            count = int(count)\n",
    "            break  # Exit the loop if conversion to int is successful\n",
    "        except ValueError:\n",
    "            print(\"Invalid input. Please enter a valid integer.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b416ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "desired_pattern = \"lego\"\n",
    "count = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584b9c15-53d5-41c0-92b7-18b741e09e89",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 2. Cartoon Effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b7aa383-9752-447c-805c-cc7a196aeaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image_path = './flower.jpeg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5c4745-ce2e-489e-84ca-79953c3773e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(input_image_path)  # Read the image from the specified path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b24c060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1129, 1280, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e83098a1-f4ca-4e6c-99c5-eeebcbe62d64",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Detect the edge in an image by using the cv2.adaptiveThreshold() function for a cartoon effect.\n",
    "def edge_mask(img, line_size, blur_value):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    edges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    return edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54a73f6-36bd-4a9e-b513-0b9c12fd8ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "line_size = 7     #A larger line size means the thicker edges that will be emphasized in the image\n",
    "blur_value = 7    #The larger blur value means fewer black noises appear in the image\n",
    "\n",
    "edges = edge_mask(img, line_size, blur_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2422114c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('edge_mask.png', edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9172c6e-25de-472d-850f-94c6218e8c4c",
   "metadata": {},
   "source": [
    "##### Color Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ed0682a-f337-4375-9cc5-dd76e10e64fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_quantization(img, k):\n",
    "    # Transform the image into a NumPy array of floating-point numbers, containing the RGB codes \n",
    "    data = np.float32(img).reshape((-1, 3))\n",
    "\n",
    "    # Determine criteria: 20 max iterations, 0.001 epsilon value for level of error\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)\n",
    "\n",
    "    # Implementing K-Means (None for initial cluster centers, it will start randomly / 10 is the number of times it will run and it will use the best of those) \n",
    "    ret, label, center = cv2.kmeans(data, k, None, criteria, 5, cv2.KMEANS_RANDOM_CENTERS)\n",
    "\n",
    "    # Cluster centers are converted to unsigned 8-bit integers (uint8) to make them suitable for representing colors in images\n",
    "    center = np.uint8(center)\n",
    "\n",
    "    # Assigns each pixel in the image to its nearest cluster center, effectively recoloring the image\n",
    "    result = center[label.flatten()]\n",
    "\n",
    "    # Result array is converted back to the original shape of the input image (img)\n",
    "    result = result.reshape(img.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da68985b-ece8-4ee4-9efb-1a2459aad126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply color quantization \n",
    "total_color = 10\n",
    "img = color_quantization(img, total_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2fa0928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('color_quantization.png', img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec383381-2386-483a-a503-d3e21a9f9296",
   "metadata": {},
   "source": [
    "##### Bilateral Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a31b42d-17fd-411b-b634-5431f9cb1307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can reduce the noise in the image by using a bilateral filter. It would give a bit blurred and sharpness-reducing effect to the image.\n",
    "d = 7            #Diameter of each pixel neighborhood\n",
    "sigmaColor=200   #A larger value of the parameter means larger areas of semi-equal color.\n",
    "sigmaSpace=200  #A larger value of the parameter means that farther pixels will influence each other as long as their colors are close enough.\n",
    "\n",
    "blurred = cv2.bilateralFilter(img, d, sigmaColor,sigmaSpace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ce71c3-4718-443b-b21e-2492fae4730f",
   "metadata": {
    "tags": []
   },
   "source": [
    "##### Combine Edge Mask with the Colored Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08adee20-651f-4e2c-8782-f3653daf5710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the edge mask that we created earlier, with the color-processed image.\n",
    "cartoon = cv2.bitwise_and(blurred, blurred, mask=edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cc69762-51e0-472f-be19-79600a6d6fc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('cartoon.png', cartoon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c58c02c-4e12-4f53-8223-6606031e217b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3. Pattern processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a2d304-417c-47ca-9911-7b1530789908",
   "metadata": {},
   "outputs": [],
   "source": [
    "if count <= 60:\n",
    "    new_width = 1000\n",
    "elif count >60 & count <= 120:\n",
    "    new_width = 1500\n",
    "elif count >120 & count <= 180:\n",
    "    new_width = 2000\n",
    "elif count >180 & count <= 240:\n",
    "    new_width = 2500\n",
    "elif count >240:\n",
    "    new_width = 3000\n",
    "\n",
    "pixel_size = int(new_width / int(count))\n",
    "\n",
    "# Get the current height and width of the image\n",
    "height, width, _ = cartoon.shape\n",
    "\n",
    "# Calculate new height while maintaining aspect ratio\n",
    "new_height = int(new_width * height / width)\n",
    "\n",
    "# Resize the image using OpenCV\n",
    "resized_img = cv2.resize(cartoon, (new_width, new_height), interpolation=cv2.INTER_NEAREST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2679237d-5df6-4696-af9d-f0925200e463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelate(image_array, pixel_size):\n",
    "    # Extracts the height and width using the shape attribute\n",
    "    img_height, img_width, _ = image_array.shape\n",
    "    \n",
    "    # Calculates the number of steps or blocks along the x and y dimensions of the image based on the pixel_size. \n",
    "    x_steps = img_width // pixel_size\n",
    "    y_steps = img_height // pixel_size\n",
    "    \n",
    "    # This array will be used to store the pixelated version of the image.\n",
    "    pixelated_image = np.zeros_like(image_array)\n",
    "\n",
    "    for y in range(y_steps):          # This outer loop iterates over the vertical blocks (rows) of the image.\n",
    "        for x in range(x_steps):      # This inner loop iterates over the horizontal blocks (columns) of the image.\n",
    "            # This block is essentially a rectangular region of the image, and its size is determined by the pixel_size variable\n",
    "            block = image_array[y * pixel_size : (y + 1) * pixel_size,\n",
    "                                x * pixel_size : (x + 1) * pixel_size]\n",
    "            # Within each block, the code calculates the average color.\n",
    "            average_color = np.mean(np.mean(block, axis=0), axis=0)\n",
    "            # The average color calculated for each block is assigned to all the pixels within that block in the pixelated_image.\n",
    "            pixelated_image[y * pixel_size : (y + 1) * pixel_size,\n",
    "                            x * pixel_size : (x + 1) * pixel_size] = average_color\n",
    "\n",
    "    return pixelated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8f5500e-5b43-4871-894c-e988bed005f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the pixelate function with the calculated pixel size\n",
    "pixelated_image = pixelate(resized_img, pixel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc724c24-04f8-43d9-b141-2c220bc09fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('pixelated_image.png', pixelated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "519778bc-1dda-4a05-af5f-aaec4e523499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific list of RGB colors, representing the available color options for the 1X1 Plate piece at the Lego store and closest thread color\n",
    "lego_data = pd.read_csv('./rgb_lego_colors.csv')\n",
    "thread_data = pd.read_csv('./rgb_threads_colors.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8923fb8d-17d0-4b42-ba37-9483070d9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrame to a list of RGB tuples\n",
    "lego_rgb_values = [(r, g, b) for r, g, b in zip(lego_data['R'], lego_data['G'], lego_data['B'])]\n",
    "thread_rgb_values = [(r, g, b) for r, g, b in zip(thread_data['R'], thread_data['G'], thread_data['B'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "379ad5cd-6d45-4871-92c2-0da0d09ebe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_quantization2(img, colors):\n",
    "    data = np.float32(img).reshape((-1, 3))\n",
    "    \n",
    "    #Diference respect to color_quantization is that this starts with the specific colors indicated as the centers of the clusters\n",
    "    centers = np.array(colors, dtype=np.float32)\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 20, 0.001)\n",
    "    _, label, center = cv2.kmeans(data, len(colors), None, criteria, 10, cv2.KMEANS_USE_INITIAL_LABELS, centers)\n",
    "    center = np.uint8(center)\n",
    "    result = center[label.flatten()]\n",
    "    result = result.reshape(img.shape)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96b4b088-0f6e-41f1-9acf-de28e8d8b350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply color quantization with the specific colors, to ensure the final result has the avaliable colors\n",
    "if desired_pattern == \"lego\":\n",
    "    specific_colors = lego_rgb_values\n",
    "elif desired_pattern == \"cross_stich\":\n",
    "    specific_colors = thread_rgb_values\n",
    "\n",
    "final_image = color_quantization2(pixelated_image, specific_colors)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "252e14e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('color_quantization2.png', final_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b739add-b3a1-45c7-8d04-e3ea1bac8b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to the BGR color space\n",
    "bgr_image = cv2.cvtColor(final_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "# Create an empty dictionary to store square colors and counts\n",
    "square_colors = {tuple(color): 0 for color in specific_colors}\n",
    "\n",
    "# Function to find the closest color in the specific_colors list\n",
    "def find_closest_color(color):\n",
    "    color = np.array(color)\n",
    "    distances = np.linalg.norm(color - specific_colors, axis=1)\n",
    "    closest_color_index = np.argmin(distances)\n",
    "    return tuple(specific_colors[closest_color_index])\n",
    "\n",
    "# Determine the size of each square based on the gridline spacing\n",
    "square_size = pixel_size\n",
    "\n",
    "# Create a copy of the image to modify\n",
    "result_image = bgr_image.copy()\n",
    "\n",
    "# Create a dictionary to store color-to-symbol mappings\n",
    "color_to_symbol = {}\n",
    "\n",
    "# Generate a list of unique symbols\n",
    "unique_symbols = list(range(1, 39+1))  \n",
    "\n",
    "# Iterate through the unique colors and assign a symbol to each\n",
    "for i, (color, _) in enumerate(square_colors.items()):\n",
    "    symbol = unique_symbols[i]  # Get the next symbol from the list\n",
    "    color_to_symbol[color] = symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8c9558e-e17d-4daf-98de-5bbbb76463e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use color_to_symbol to map colors to symbols in result_image\n",
    "\n",
    "for y in range(0, bgr_image.shape[0], square_size):\n",
    "    for x in range(0, bgr_image.shape[1], square_size):\n",
    "        square = bgr_image[y:y+square_size, x:x+square_size]\n",
    "        square_color = tuple(np.mean(square, axis=(0, 1), dtype=int))\n",
    "        closest_color = find_closest_color(square_color)\n",
    "              \n",
    "        # Increment the count of the closest color in square_colors\n",
    "        square_colors[closest_color] += 1\n",
    "        \n",
    "        # Replace the colors in the square with the closest color\n",
    "        result_image[y:y+square_size, x:x+square_size] = closest_color\n",
    "\n",
    "# Convert the modified image back to RGB color space\n",
    "result_image_rgb = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6f1f671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('result_image_rgb.png', result_image_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "315668a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use color_to_symbol to map colors to symbols in result_image\n",
    "\n",
    "for y in range(0, bgr_image.shape[0], square_size):\n",
    "    for x in range(0, bgr_image.shape[1], square_size):\n",
    "        square = bgr_image[y:y+square_size, x:x+square_size]\n",
    "        square_color = tuple(np.mean(square, axis=(0, 1), dtype=int))\n",
    "        closest_color = find_closest_color(square_color)\n",
    "        \n",
    "        # Get the symbol for the closest color from the dictionary\n",
    "        #symbol = color_to_symbol.get(closest_color, 'N/A')  # Add a default value for debugging\n",
    "              \n",
    "        # Increment the count of the closest color in square_colors\n",
    "        #square_colors[closest_color] += 1\n",
    "        \n",
    "        # Replace the colors in the square with the closest color\n",
    "        result_image[y:y+square_size, x:x+square_size] = closest_color\n",
    "\n",
    "        \n",
    "        # Overlay the symbol on top of the square\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = (pixel_size / 50)\n",
    "        font_color = (0, 0, 0)  # Black font color\n",
    "        font_thickness = 1\n",
    "              \n",
    "        # Calculate the text size to determine the width and height of the text\n",
    "        (text_width, text_height), _ = cv2.getTextSize(str(symbol), font, font_scale, font_thickness)\n",
    "\n",
    "        # Calculate the position (org) to center the text within the square\n",
    "        x_centered = x + (square_size - text_width) // 2\n",
    "        y_centered = y + (square_size + text_height) // 2\n",
    "        org = (x_centered, y_centered)\n",
    "\n",
    "        # Overlay the symbol on top of the square\n",
    "        cv2.putText(result_image, str(symbol), org, font, font_scale, font_color, font_thickness)\n",
    "\n",
    "\n",
    "\n",
    "# Convert the modified image back to RGB color space\n",
    "result_image_rgb_symbol = cv2.cvtColor(result_image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "437fae3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('result_image_rgb_symbol.png', result_image_rgb_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2b42a8e-8345-45af-a0f5-4eacba67eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the gridline spacing based on pixel size\n",
    "gridline_spacing = pixel_size\n",
    "\n",
    "# Create a copy of the pixelated image to draw gridlines on\n",
    "image_with_gridlines = result_image_rgb.copy()\n",
    "\n",
    "# Draw vertical gridlines -  iterates over the coordinates of the image and draws black lines \n",
    "for x in range(0, pixelated_image.shape[1], gridline_spacing):\n",
    "    cv2.line(image_with_gridlines, (x, 0), (x, pixelated_image.shape[0]), (0, 0, 0), 1)  \n",
    "\n",
    "# Draw horizontal gridlines  -  iterates over the coordinates of the image and draws black lines \n",
    "for y in range(0, pixelated_image.shape[0], gridline_spacing):\n",
    "    cv2.line(image_with_gridlines, (0, y), (pixelated_image.shape[1], y), (0, 0, 0), 1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d51824f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the pixelated image to draw gridlines on\n",
    "image_with_gridlines_symbols = result_image_rgb_symbol.copy()\n",
    "\n",
    "# Draw vertical gridlines -  iterates over the coordinates of the image and draws black lines \n",
    "for x in range(0, pixelated_image.shape[1], gridline_spacing):\n",
    "    cv2.line(image_with_gridlines_symbols, (x, 0), (x, pixelated_image.shape[0]), (0, 0, 0), 1)  \n",
    "\n",
    "# Draw horizontal gridlines  -  iterates over the coordinates of the image and draws black lines \n",
    "for y in range(0, pixelated_image.shape[0], gridline_spacing):\n",
    "    cv2.line(image_with_gridlines_symbols, (0, y), (pixelated_image.shape[1], y), (0, 0, 0), 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2a20ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('image_with_gridlines_symbols.png', image_with_gridlines_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d38c829-06ae-4c5b-bc7a-da28b0421425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('image_with_gridlines.png', image_with_gridlines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4055ebe-7a66-4e66-b124-e410fdbecc95",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 4. Prepare legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44ce7c93-28bc-44e4-aec7-e8fdc8924df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the dictionary to a DataFrame\n",
    "colors_total = pd.DataFrame(list(square_colors.items()), columns=[\"color\", \"count\"])\n",
    "symbols_total = pd.DataFrame(list(color_to_symbol.items()), columns=[\"color\", \"symbol\"])\n",
    "\n",
    "colors_used = pd.merge(colors_total, symbols_total, on='color', how='left')\n",
    "\n",
    "# Drop rows where Count is zero\n",
    "colors_used = (colors_used[colors_used[\"count\"] != 0]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61cd8231-a1d6-4dde-be61-4ac06ab7eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_color(x):\n",
    "    return tuple(map(int, str(x).replace(' ', '').strip('()').split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "79a39580-0ddf-45a1-b194-e66eff4996e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_used['color'] = colors_used['color'].apply(clean_color)\n",
    "lego_data['color'] = lego_data['color'].apply(clean_color)\n",
    "thread_data['color'] = thread_data['color'].apply(clean_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28b2c14f-d080-40db-b804-04714fc9c3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if desired_pattern == \"lego\":\n",
    "    color_table = pd.merge(colors_used, lego_data, left_on='color', right_on = 'color', how='left')\n",
    "elif desired_pattern == \"cross_stich\":\n",
    "    color_table = pd.merge(colors_used, thread_data, left_on='color', right_on = 'color', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6bd954e2-b8c1-4f5c-b8f6-e1fad92b4522",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['color','R', 'G','B',]\n",
    "color_table.drop(columns_to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4e58f50-af7f-46d8-8450-a74ed408a381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>symbol</th>\n",
       "      <th>LEGO Name</th>\n",
       "      <th>LEGO Name 2</th>\n",
       "      <th>Element ID</th>\n",
       "      <th>Design ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>652</td>\n",
       "      <td>17</td>\n",
       "      <td>Dark Green</td>\n",
       "      <td>141 ['Earth Green', 'EARTH GREEN']</td>\n",
       "      <td>6055169</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>652</td>\n",
       "      <td>19</td>\n",
       "      <td>Green</td>\n",
       "      <td>28 ['Dark green', 'DK.GREEN']</td>\n",
       "      <td>302428</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>443</td>\n",
       "      <td>20</td>\n",
       "      <td>Bright Green</td>\n",
       "      <td>37 ['Bright Green', 'BR.GREEN']</td>\n",
       "      <td>6401817</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>21</td>\n",
       "      <td>Lime</td>\n",
       "      <td>119 ['Br. yellowish green', 'BR.YEL-GREEN']</td>\n",
       "      <td>4621557</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>Olive Green</td>\n",
       "      <td>330 ['Olive Green', 'OLIVE GREEN']</td>\n",
       "      <td>6058245</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1658</td>\n",
       "      <td>24</td>\n",
       "      <td>Yellow</td>\n",
       "      <td>24 ['Bright yellow', 'BR.YEL']</td>\n",
       "      <td>302424</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>345</td>\n",
       "      <td>28</td>\n",
       "      <td>Dark Brown</td>\n",
       "      <td>308 ['Dark Brown', 'DK. BROWN']</td>\n",
       "      <td>6194729</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>466</td>\n",
       "      <td>30</td>\n",
       "      <td>Dark Orange</td>\n",
       "      <td>38 ['Dark Orange', 'DK.ORA']</td>\n",
       "      <td>6186012</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>655</td>\n",
       "      <td>31</td>\n",
       "      <td>Orange</td>\n",
       "      <td>106 ['Bright orange', 'BR.ORANGE']</td>\n",
       "      <td>4524929</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>332</td>\n",
       "      <td>34</td>\n",
       "      <td>Reddish Brown</td>\n",
       "      <td>192 ['Reddish Brown', 'RED. BROWN']</td>\n",
       "      <td>4221744</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>926</td>\n",
       "      <td>38</td>\n",
       "      <td>Black</td>\n",
       "      <td>26 ['Black', 'BLACK']\\n342 ['CONDUCT. BLACK']</td>\n",
       "      <td>302426</td>\n",
       "      <td>3024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    count  symbol      LEGO Name   \n",
       "0     652      17     Dark Green  \\\n",
       "1     652      19          Green   \n",
       "2     443      20   Bright Green   \n",
       "3       5      21           Lime   \n",
       "4      82      22    Olive Green   \n",
       "5    1658      24         Yellow   \n",
       "6     345      28     Dark Brown   \n",
       "7     466      30    Dark Orange   \n",
       "8     655      31         Orange   \n",
       "9     332      34  Reddish Brown   \n",
       "10    926      38          Black   \n",
       "\n",
       "                                      LEGO Name 2  Element ID    Design ID  \n",
       "0              141 ['Earth Green', 'EARTH GREEN']      6055169        3024  \n",
       "1                   28 ['Dark green', 'DK.GREEN']       302428        3024  \n",
       "2                 37 ['Bright Green', 'BR.GREEN']      6401817        3024  \n",
       "3     119 ['Br. yellowish green', 'BR.YEL-GREEN']      4621557        3024  \n",
       "4              330 ['Olive Green', 'OLIVE GREEN']      6058245        3024  \n",
       "5                  24 ['Bright yellow', 'BR.YEL']       302424        3024  \n",
       "6                 308 ['Dark Brown', 'DK. BROWN']      6194729        3024  \n",
       "7                    38 ['Dark Orange', 'DK.ORA']      6186012        3024  \n",
       "8              106 ['Bright orange', 'BR.ORANGE']      4524929        3024  \n",
       "9             192 ['Reddish Brown', 'RED. BROWN']      4221744        3024  \n",
       "10  26 ['Black', 'BLACK']\\n342 ['CONDUCT. BLACK']       302426        3024  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c2d8e6c-2ade-4999-a903-5de3e2b0f6ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6216"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_table['count'].sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
